{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pytorch_lightning.metrics.classification import F1\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"../dataset\"\n",
    "images_root = os.path.join(data_root, \"images_all\")\n",
    "masks_root = os.path.join(data_root, \"masks_all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_dist = os.path.join(data_root, \"test_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scripts_path = \"../scripts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(scripts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import constants as const\n",
    "\n",
    "from data_loader import MelanomaClassificationDataset, MelanomaSegmentationDataset\n",
    "from seg_train_utils import get_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(test_data_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr = test_data.copy()\n",
    "test_data_tr = test_data_tr.replace({\"class\": {\"benign\": 0, \"malignant\": 1}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We have {} benign data points\".format(len(test_data_tr[test_data_tr[\"class\"] == 0])))\n",
    "print(\"We have {} malignant data points\".format(len(test_data_tr[test_data_tr[\"class\"] == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset_classification = MelanomaClassificationDataset(csv_file = test_data_tr, \n",
    "                                             root_dir = images_root,\n",
    "                                             augmentation = None,\n",
    "                                             preprocessing = MelanomaClassificationDataset.get_default_preprocessing())\n",
    "\n",
    "\n",
    "test_dataset_segmentation = MelanomaSegmentationDataset(csv_file = test_data_tr,\n",
    "                                                        root_dir = (images_root, masks_root),\n",
    "                                                        augmentation = None,\n",
    "                                                        preprocessing = MelanomaSegmentationDataset.get_default_preprocessing())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader_classificaiton = get_data_loader(test_dataset_classification, batch_size = const.batch_size_val, shuffle=False, num_workers = 0)\n",
    "\n",
    "test_loader_segmentation = get_data_loader(test_dataset_segmentation, batch_size = const.batch_size_val, shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restore model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = const.DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification = torch.load(\"../models/classification_model_inception_v3.279314.pth\")\n",
    "model_classification.eval()\n",
    "\n",
    "model_segmentation = torch.load(\"../models/segmentation_model_xception_backbone.pth\")\n",
    "model_segmentation.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform predictions and collect results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pd.DataFrame(columns = [\"prediction\", \"ground_truth\"])\n",
    "\n",
    "with torch.no_grad(): \n",
    "    outer_idx = 0\n",
    "    for image, label in tqdm(test_loader_segmentation):\n",
    "        image = image.to(device)\n",
    "        mask = label.to(device)\n",
    "        \n",
    "        ### SEGMENTATION ###\n",
    "\n",
    "        # Perform prediction for mask            \n",
    "        mask_pred = model_segmentation(image)\n",
    "\n",
    "        # Post-process the results\n",
    "        mask_pred[mask_pred >= 0.5] = 1\n",
    "        mask_pred[mask_pred < 0.5] = 0\n",
    "        \n",
    "        # Apply mask on image\n",
    "        idx = (mask_pred == 0)[0]\n",
    "        \n",
    "        masked_image = image * mask_pred.int().float()\n",
    "        \n",
    "        ### CLASSIFICATION ###\n",
    "        \n",
    "        # Perform prediction on masked image\n",
    "        outputs = model_classification(masked_image)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        \n",
    "        # Retrieve grount truth class\n",
    "        _, label = test_dataset_classification.__getitem__(outer_idx)\n",
    "        \n",
    "        res = res.append({\n",
    "            \"prediction\": preds.item(), \n",
    "            \"ground_truth\": label.item()\n",
    "        }, ignore_index = True)\n",
    "        \n",
    "        outer_idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform analyzis of the outputs for a specific dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_all = res.prediction.values.astype(int)\n",
    "gt_all = res.ground_truth.values.astype(int)\n",
    "\n",
    "conf_matrix = confusion_matrix(gt_all, preds_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision: {:.2f}\".format(precision_score(gt_all, preds_all)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(gt_all, preds_all)))\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(gt_all, preds_all)))\n",
    "print(\"F1 score: {:.2f}\".format(f1_score(gt_all, preds_all)))\n",
    "print(\"Confusion matrix:\\n{}\\n{}\".format(conf_matrix[0], conf_matrix[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
